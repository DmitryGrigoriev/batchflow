{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ready to use TensorFlow model with a simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# the following line is not required if BatchFlow is installed as a python package.\n",
    "sys.path.append(\"../..\")\n",
    "from batchflow import Pipeline, B, C, F, V, Batch, ImagesBatch, action\n",
    "from batchflow.opensets import MNIST, CIFAR10\n",
    "from batchflow.models.tf import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you comment out the line below, the training will take much more time and the accuracy might slightly decrease.\n",
    "So it is always a good idea to import [best_practice](https://analysiscenter.github.io/batchflow/intro/best_practice.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from batchflow import best_practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH_SIZE might be increased for modern GPUs with lots of memory (4GB and higher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make function convetring the labels more or equal 5 to 1 and 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_two_class(label):\n",
    "    return np.where(label >= 5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MNIST](http://yann.lecun.com/exdb/mnist/) is a dataset of handwritten digits frequently used as a baseline for machine learning tasks.\n",
    "\n",
    "Downloading MNIST database might take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DownloadingDownloadingDownloadingDownloading    http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gzhttp://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gzhttp://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gzhttp://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "\n",
      "ExtractingExtractingExtractingExtracting    C:\\Users\\AACE~1\\AppData\\Local\\Temp\\train-labels-idx1-ubyte.gzC:\\Users\\AACE~1\\AppData\\Local\\Temp\\t10k-images-idx3-ubyte.gzC:\\Users\\AACE~1\\AppData\\Local\\Temp\\train-images-idx3-ubyte.gzC:\\Users\\AACE~1\\AppData\\Local\\Temp\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also predefined CIFAR10 and CIFAR100 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a pipeline config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config allows to create flexible pipelines which take parameters.\n",
    "\n",
    "For instance, if you put a model type into config, you can run a pipeline against different models.\n",
    "\n",
    "See [a list of available models](https://analysiscenter.github.io/batchflow/intro/tf_models.html#ready-to-use-models) to choose the one which fits you best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = dict(model=ResNet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a template pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A template pipeline is not linked to any dataset. It's just an abstract sequence of actions, so it cannot be executed, but it serves as a convenient building block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add our new function to pipeline and change the number of classes to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_template = (Pipeline(config=config)\n",
    "                .init_variable('loss_history', init_on_each_run=list)\n",
    "                .init_variable('current_loss')\n",
    "                .init_model('dynamic', C('model'), 'conv_nn',\n",
    "                            config={'inputs': dict(images={'shape': B('image_shape')},\n",
    "                                                   labels={'classes': 2}),\n",
    "                                    'initial_block/inputs': 'images'})\n",
    "                .to_array()\n",
    "                .apply_transform(making_two_class, src='labels', dst='labels')\n",
    "                .train_model('conv_nn', fetches='loss', images=B('images'), labels=B('labels'),\n",
    "                             save_to=V('current_loss'))\n",
    "                .update_variable('loss_history', V('current_loss'), mode='a')\n",
    "                \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a dataset to a template pipeline to create a runnable pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pipeline = (train_template << dataset.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that our labels are two class now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline.next_batch(BATCH_SIZE).labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 937/937 [28:38<00:00,  1.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<batchflow.pipeline.Pipeline at 0x2700cee95f8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline.run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=True, bar=True, prefetch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the progress bar often increments by 2 at a time - that's prefetch in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not give much here, though, since almost all time is spent in model training which is performed under a thread-lock one batch after another without any parallelism (otherwise the model would not learn anything as different batches would rewrite one another's model weights updates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is much faster than training, but if you don't have GPU it would take some patience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add our new function to a test pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 156/156 [00:14<00:00, 11.10it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pipeline = (dataset.test.p\n",
    "                .import_model('conv_nn', train_pipeline)\n",
    "                .init_variable('predictions') \n",
    "                .init_variable('metrics', init_on_each_run=None) \n",
    "                .to_array()\n",
    "                .apply_transform(making_two_class, src='labels', dst='labels')\n",
    "                .predict_model('conv_nn', fetches='predictions', images=B('images'), labels=B('labels'),\n",
    "                               save_to=V('predictions'))\n",
    "                .gather_metrics('class', targets=B('labels'), predictions=V('predictions'),\n",
    "                                fmt='logits', axis=-1, save_to=V('metrics'), mode='w')\n",
    "                .run(BATCH_SIZE, shuffle=True, n_epochs=1, drop_last=True, bar=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the accumulated [metrics information](https://analysiscenter.github.io/batchflow/intro/models.html#model-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = test_pipeline.get_variable('metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easiliy calculate any metrics we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.evaluate('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'false_negative_rate': 0.03571428571428571, 'false_positive_rate': 0.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.evaluate(['false_positive_rate', 'false_negative_rate'], multiclass=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "After learning the model, you may need to save it. It's easy to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pipeline.save_model('conv_nn', path='path/to/save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [the image augmentation tutorial](./06_image_augmentation.ipynb) or return to the [table of contents](./00_description.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
